{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading global-shark-attacks.zip to C:\\Users\\juanp\\Ironhack\\proyectos\\pandas-project\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/548k [00:00<?, ?B/s]\n",
      "100%|##########| 548k/548k [00:00<00:00, 5.39MB/s]\n",
      "100%|##########| 548k/548k [00:00<00:00, 5.34MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d teajay/global-shark-attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x attacks.csv\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf global-shark-attacks.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data\\\\attacks.csv\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M  ...   \n",
       "3              Arrawarra Headland      Surfing             male    M  ...   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  ...   \n",
       "\n",
       "          Species           Investigator or Source                       pdf  \\\n",
       "0      White shark                R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1              NaN  K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2              NaN  K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3        2 m shark                  B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4  Tiger shark, 3m                       A .Kipper      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "3    2018.06.08         6300.0         NaN         NaN  \n",
       "4    2018.06.04         6299.0         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 24)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a number of columns that wont be relevant for the analysis, like \"pdf\" of \"href formula\", and others whose meaning cannot be interpreted easily, like \"Unnamed 22\" or \"Original order\". This columsn can be dropped as they wont be useful. Also, the column \"Case Number\" and \"Date\" seem to contain the same date information with different formats, so we can delete one of them and work with the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Date\",\"Name\",\"Investigator or Source\",\"pdf\",\"href formula\",\"href\",\"Case Number.1\",\"Case Number.2\",\n",
    "                 \"original order\",\"Unnamed: 22\", \"Unnamed: 23\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number    17021\n",
       "Year           19423\n",
       "Type           19425\n",
       "Country        19471\n",
       "Area           19876\n",
       "Location       19961\n",
       "Activity       19965\n",
       "Sex            19986\n",
       "Age            22252\n",
       "Injury         19449\n",
       "Fatal (Y/N)    19960\n",
       "Time           22775\n",
       "Species        22259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a great number of rows that contain a lot of Nan values. An way to deal with them would be to drop all rows that have a 100% of NaN values, however, there are rows that have many NaN values without reaching the 100%. In order keep the maximun amount of information possible,the **thresh** parameter of the **dropna()** built-in function will be used to determine the maximum number of NaN values allowed per row. In this case the parameter will be set to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, thresh=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6301, 13)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have deleted around 19,000 rows of the dataset, almost 4/5 of the total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to treat the remaining NaN values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to fill the NaN values in a dataset, and each one depends on a series of factors like the type of the column, the kind of analysis, etc. In this case, two approaches are going to be taken. Those NaN values in string type columns are going to be replaced by **Unknown**, as it is something that should not be guessed nor inferred. In the case of data tyoe columns, even though they have not yet been transformed, are going to be repalced with the previous value because it can be assumed that they follow a certain order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When trying to replace the NaN values of categorical columns, there is an error related to the **Species** column, at is because it has a white space at the end. This can be solved later, but in order to have all the columns with the same format lets do it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Species \":\"Species\"},inplace  =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Sex \":\"Sex\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Fatal (Y/N)\":\"Fatal\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Case Number\":\"Case_Number\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the NaN with Unknown of categorical values (object)\n",
    "data[[\"Type\", \"Country\", \"Area\", \"Activity\", \"Injury\"\n",
    "            ,\"Sex \", \"Fatal (Y/N)\", \"Species\"]] = data[[\"Type\", \"Country\", \"Area\", \"Activity\", \"Injury\"\n",
    "                         ,\"Sex \", \"Fatal (Y/N)\",\"Species\"]].fillna(\"Unknown\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the case of 'Year' and 'Time' we're going to fill NaN values with the previous one, as we assume that they\n",
    "#follow a certain order, and doing this is better that filling them with 'NONE'\n",
    "\n",
    "data[[\"Case Number\",\"Time\", \"Year\"]] = data[[\"Case Number\",\"Time\", \"Year\"]].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Column Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check each of the colums to see what corrections need to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(data):\n",
    "    return data.sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(column):\n",
    "    '''\n",
    "    This function returns the value_counts() result of a column as a dictionary sorted by key in ascending order.\n",
    "    Easier to examine.\n",
    "    Args: the column of interest in the format of df.column or df[\"columnd\"]\n",
    "    '''\n",
    "    s = (column.value_counts())\n",
    "    dictionary =  s.to_dict()\n",
    "    return collections.OrderedDict(sorted(dictionary.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = counts(data.Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that should be noticed is that ther a 125 attack in year 0, which makes no sense. Also, there are records of attacks taking place in years that are too ancient. This may be typing errors, so, instead of deleting all those records, and losing all the information, when analyzing the **Year** column a threshold will be set to avoid taking this attypical years into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should also be mentioned that the years have decimals, which is not possible. Therefore, lets remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Year = data.Year.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The df has been safed as a csv so that the progress is not lost if jupyter notebook is closed \n",
    "data.to_csv(r'C:\\Users\\juanp\\Ironhack\\proyectos\\pandas-project\\data\\data_year.csv' , index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = pd.read_csv(\"data\\data_year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = counts(data.Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Country** column is a huge mess. There are countries that are instanecs that have the same name but one has an extra space at the end, some have two possible locations, etc. The first thing that must be done is to make sure all names have the same capitalization, in this case uppercased, and delete all extra spaces. Afterwards, the a function will be created to deal with the different pattern cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete whitespace at the end and beggining of string\n",
    "data.Country = data.Country.str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Country = data.Country.str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uppercase\n",
    "data.Country = data.Country.apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\juanp\\Ironhack\\proyectos\\pandas-project\\data\\data.csv' , index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we are going to clean the 'Case Number' column in order to have just one format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We delele the fragemnts that come after the last '.'\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'(\\.\\w$)', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the combination of uppercase and number after a '.'\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'\\.[A-Z]\\w', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the combination of upper or lowercase that come after a '.'\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'\\.[A-Z]|[a-z]', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the last '.' \n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'\\.$', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the '.' and '&' combination\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'\\.\\ \\&', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the '/'\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'\\/', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the combination of '.' or '-' and 0-1 letter after\n",
    "\n",
    "data_clean[\"Case Number\"] = data_clean[\"Case Number\"].replace(to_replace = r'(\\.|-)\\w?$', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original order</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6303.0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boat</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>F</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302.0</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Standing</td>\n",
       "      <td>F</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301.0</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Surfinging</td>\n",
       "      <td>M</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300.0</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Surfinging</td>\n",
       "      <td>M</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299.0</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>Diving</td>\n",
       "      <td>M</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Diving</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>16h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Diving</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>16h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>16h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>16h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>SRI LANKA</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>16h00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6302 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Case Number    Year        Type    Country               Area  \\\n",
       "original order                                                                 \n",
       "6303.0          2018.06.25  2018.0        Boat        USA         California   \n",
       "6302.0          2018.06.18  2018.0  Unprovoked        USA            Georgia   \n",
       "6301.0          2018.06.09  2018.0     Invalid        USA             Hawaii   \n",
       "6300.0          2018.06.08  2018.0  Unprovoked  AUSTRALIA    New South Wales   \n",
       "6299.0          2018.06.04  2018.0    Provoked     MEXICO             Colima   \n",
       "...                    ...     ...         ...        ...                ...   \n",
       "6.0                ND.0005     0.0  Unprovoked  AUSTRALIA  Western Australia   \n",
       "5.0                ND.0004     0.0  Unprovoked  AUSTRALIA  Western Australia   \n",
       "4.0                ND.0003     0.0  Unprovoked        USA     North Carolina   \n",
       "3.0                ND.0002     0.0  Unprovoked     PANAMA            Unknown   \n",
       "2.0                ND.0001     0.0  Unprovoked  SRI LANKA   Eastern Province   \n",
       "\n",
       "                  Activity Sex   \\\n",
       "original order                    \n",
       "6303.0             Surfing    F   \n",
       "6302.0            Standing    F   \n",
       "6301.0          Surfinging    M   \n",
       "6300.0          Surfinging    M   \n",
       "6299.0              Diving    M   \n",
       "...                    ...  ...   \n",
       "6.0                 Diving    M   \n",
       "5.0                 Diving    M   \n",
       "4.0               Swimming    M   \n",
       "3.0                Unknown    M   \n",
       "2.0               Swimming    M   \n",
       "\n",
       "                                                           Injury Fatal (Y/N)  \\\n",
       "original order                                                                  \n",
       "6303.0          No injury to occupant, outrigger canoe and pad...           N   \n",
       "6302.0                                 Minor injury to left thigh           N   \n",
       "6301.0               Injury to left lower leg from surfboard skeg           N   \n",
       "6300.0                                  Minor injury to lower leg           N   \n",
       "6299.0          Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "...                                                           ...         ...   \n",
       "6.0                                                         FATAL           Y   \n",
       "5.0                                                         FATAL           Y   \n",
       "4.0                                                         FATAL           Y   \n",
       "3.0                                                         FATAL           Y   \n",
       "2.0             FATAL. \"Shark bit him in half, carrying away t...           Y   \n",
       "\n",
       "                 Time  \n",
       "original order         \n",
       "6303.0          18h00  \n",
       "6302.0          14h00  \n",
       "6301.0          07h45  \n",
       "6300.0          07h45  \n",
       "6299.0          07h45  \n",
       "...               ...  \n",
       "6.0             16h00  \n",
       "5.0             16h00  \n",
       "4.0             16h00  \n",
       "3.0             16h00  \n",
       "2.0             16h00  \n",
       "\n",
       "[6302 rows x 10 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We export the clean dataframe as csv.\n",
    "\n",
    "data_clean.to_csv(r'C:\\Users\\juanp\\Ironhack\\pandas-project\\data\\data_clean.csv' , index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
